<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Zhanxin Wu</title>
  <meta name="author" content="Zhanxin Wu">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="general_images/nus-logo-small.png">
</head>


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JT12TT4BJQ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-JT12TT4BJQ');
</script>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhanxin Wu</name>
              </p>
              <!-- <p style="text-align: center;"><strong>Email</strong>: zhanxinwu [at] u.nus.edu </p> -->

              <p>I am a second-year master student majoring in Computer Science at <a href="https://nus.edu.sg/">National University of Singapore (NUS)</a> advised by <a href="https://www.comp.nus.edu.sg/~dyhsu/">Prof David Hsu</a>. 
                I work at the intersection of robotics and machine learning, with the goal of enabling robots to work intellectually and seamlessly in the real world. Currently, I am working on open scene graphs for open-world object goal navigation at the <a href="https://adacomp.comp.nus.edu.sg/">NUS Adacomp</a>.

              <p>
                Previously, I worked as an Undergraduate Research Assistant with <a href="https://www.zhaojunhua.org/"> Prof Junhua Zhao</a> in the Lab of Energy Internet. After that, I was a Robotics Institute Summer Scholar (RISS)  
                 at <a href="https://www.ri.cmu.edu/">Carnegie Mellon University</a> advised by <a href="https://www.cs.cmu.edu/~./jeanoh/">Prof Jean Oh</a>.
                I received my B.E. in Computer Science and Engineering from the <a href="https://www.cuhk.edu.cn/en">Chinese University of Hongkong, Shenzhen (CUHKSZ)</a> in 2022. 
                
                <p style="text-align:center">
                  <a href="mailto:zhanxinwu@u.nus.edu">Email</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=e5ymbE8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                  <a href="https://github.com/iko0725">Github</a> &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/zhanxin-wu-736204262/">LinkedIn</a>
                </p>

              </p>
            </td>
            <td style="padding:2.5%;width:20%;max-width:20%">
              <!-- <a href="general_images/zhanxinwu_circle.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="general_images/zhanxinwu_circle.jpg" class="hoverZoomLink"></a> -->
              <a href="general_images/zhanxinwu_circle2.png"><img style="width:100%;max-width:100%" alt="profile photo" src="general_images/zhanxinwu_circle2.png" class="hoverZoomLink"></a>
            </td>

          
          </tr>
          


        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
          
              <!-- <heading>Research</heading>
              <p>
                I'm interested in machine learning, navigation, and large models. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <heading>Research</heading>
              <p>
                More in progress...
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


<!-- highlighted papers should use bgcolor="#ffffd0" -->

<tr>
  <td style="padding:0px;width:15%;vertical-align:middle">
    <div class="one">
      <div class="two" id='tidy_image'><video  width=100% height=100% muted autoplay loop>
        <source src="projects/invariant_rep/iser_5x.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video>
      </div>
    </div>
  </td>
  <td style="padding:20px;width:85%;vertical-align:middle">
    <a href="https://zhanxinwu.com">
      <papertitle>Invariance is Key to Generalization: Examining the Role of Representation in Sim-to-Real Transfer for Visual Navigation</papertitle>
    </a>
    <br>
    <a href="https://www.albertboai.com/">Bo Ai</a>,
    <strong>Zhanxin Wu</strong>,
      <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>
    <br>

    <em><a href="http://ifrr.org/iser" class="underline-on-hover">International Symposium on Experimental Robotics (ISER)</a></em>, 2023 <br>
    To appear in <em><a href="https://www.springer.com/series/15556" class="underline-on-hover">Springer Proceedings in Advanced Robotics (SPAR)</a></em>
    <br>

    <a href="https://arxiv.org/abs/2310.15020">Paper</a>
    <p>
      This work examines, experimentally and theoretically, one representation that enables visual navigation policies solely trained in the Habitat simulator to generalize to real-world scenes, both indoor and outdoors.
    </p>
  </td>
</tr>


<tr>
  <td style="padding:0px;width:15%;vertical-align:middle">
    <div class="one">
      <div class="two" id='tidy_image'><video  width=100% height=100% muted autoplay loop>
      <source src="projects/llm-tidy-rssw/LLM_TAMP_RSSW.mp4" type="video/mp4">
      Your browser does not support the video tag.
      </video>
      </div>
    </div>
  </td>
  <td style="padding:20px;width:85%;vertical-align:middle">
    <a href="https://openreview.net/pdf?id=vuSI9mhDaBZ">
      <papertitle>Integrating Common Sense and Planning with Large Language Models for Room Tidying</papertitle>
    </a>
    <br>
    <strong>Zhanxin Wu</strong>,
    <a href="https://www.albertboai.com/" >Bo Ai</a>,
      <a href="https://www.comp.nus.edu.sg/~dyhsu/" >David Hsu</a>
    <br>

    <em><a href="https://zt-yang.github.io/rss23-l4tamp-workshop/" class="underline-on-hover">Robotics: Science and Systems (RSS) Learning for Task and Motion Planning Workshop</a></em>, 2023 <br>

    <a href="https://openreview.net/pdf?id=vuSI9mhDaBZ">Paper</a>
    /
    <a href="https://zt-yang.github.io/rss23-l4tamp-workshop/assets/pdf/Posters/07.pdf">Poster</a>
    <p>
    A framework that enables an agent to put misplaced objects back in place with partial map information by exploiting commonsense knowledge in large language models (LLMs).
    </p>
  </td>
</tr>

</tr>
  <td style="padding:0px; width:15%;vertical-align:middle">
    <div class="two" id='contrax_image'><video width=100% height=100% muted autoplay loop>
    <source src="" type="video/mp4">
    Your browser does not support the video tag.
    </video></div>
    <div style="vertical-align:middle; text-align: center;" >
    <img src="projects/semseg-nav/framework.png" width="100%" height= "100%" alt="framework">
    </div>
  </td>   
  

  <td style="padding:20px;width:85%;vertical-align:middle">
    <a href="https://riss.ri.cmu.edu/wp-content/uploads/2021/10/2021-CMU-RoboticsInstitute_SummerScholars-WorkingPapersJournal-Sized-compressed.pdf">
      <papertitle>Semantic Segmentation in Complex Scenes for Robotics Navigation</papertitle>
    </a>
    <br>
    <strong>Zhanxin Wu</strong>,
    <a>Xinjie Yao</a>,
    <a href="https://www.cs.cmu.edu/~./jeanoh/">Jean Oh</a>
    <br>

    <em>CMU Robotics Institute Summer Scholar’ Working Papers Journals</em>, 2021 <br>

    <a href="https://riss.ri.cmu.edu/wp-content/uploads/2021/10/2021-CMU-RoboticsInstitute_SummerScholars-WorkingPapersJournal-Sized-compressed.pdf">Paper</a>
    /
    <a href="https://www.youtube.com/watch?v=D51mHaqptzE">Video</a>
    /
    <a href="https://drive.google.com/file/d/1uvoVNt3sjMBrKTS4uSIRwuRpfjhAAff8/view">Poster</a>
    <p>
      A lightweight framework for semantic segmentation to recover information from uninformative pixels and improve 3D semantic understanding of scenes.
    </p>
  </td>
</tr>



</tr> 
<td style="padding:0px; width:15%;vertical-align:middle">
  <div class="two" id='contrax_image'><video width=100% height=100% muted autoplay loop>
  <source src="" type="video/mp4">
  Your browser does not support the video tag.
  </video></div>
  <div style="vertical-align:middle; text-align: center;" >
  <img src="projects/carbon-footprint/results.png" width="100%" height= "100%" alt="framework">
  </div>
</td>   
<td style="padding:20px;width:85%;vertical-align:middle">
  <a href="https://ieeexplore.ieee.org/document/9721566" >
    <papertitle>Real-Time Corporate Carbon Footprint Estimation Methodology Based on Appliance Identification</papertitle>
  </a>
  <br>
  <a>Guolong Liu</a>,
  <a>Jinjie Liu</a>,
  <a>Junhua Zhao</a>,
  <a>Jing Qiu</a>,
  <a>Yiru Mao</a>,
  <strong>Zhanxin Wu</strong>,
  <a>Fushuan Wen </a>

  <br>

  <em>IEEE Transactions on Industrial Informatics</em>, 2022 <br>

  <a href="https://ieeexplore.ieee.org/document/9721566">Paper</a>
  <p>
    Formulated corporate carbon footprint estimation problem and proposed the first Methodology to estimate the direct and indirect carbon emissions of factories in real time
  </p>
</td>
</tr>


</tr>
<td style="padding:0px; width:15%;vertical-align:middle">
  <div class="two" id='contrax_image'><video width=100% height=100% muted autoplay loop>
  <source src="" type="video/mp4">
  Your browser does not support the video tag.
  </video></div>
  <div style="vertical-align:middle; text-align: center;" >
  <img src="projects/temporal-cnn/result.png" width="100%" height= "100%" alt="framework">
  </div>
</td>  
<td style="padding:20px;width:85%;vertical-align:middle">
  <a href="https://ieeexplore.ieee.org/abstract/document/9713379">
    <papertitle>A Temporal Convolutional Neural Network with Attention Mechanism for Industrial Non-Intrusive Load Monitoring</papertitle>
  </a>
  <br>
  <a>Guolong Liu</a>,
  <a>Gaoqi Liang</a>,
  <a>Huan Zhao</a>,
  <a>Junhua Zhao</a>,
  <a>Jinjie Liu</a>,
  <strong>Zhanxin Wu</strong>

  <br>

  <em>IEEE Energy Internet and Energy System Integration (EI2)</em>, 2021 <br>

  <a href="https://ieeexplore.ieee.org/abstract/document/9713379">Paper</a>
  <p>
    A temporal convolutional neural network with attention mechanism based method is proposed for industrial non-intrusive load monitoring.
  </p>
</td>
</tr>



</tr>  
<td style="padding:0px; width:15%;vertical-align:middle">
  <div class="two" id='contrax_image'><video width=100% height=100% muted autoplay loop>
  <source src="" type="video/mp4">
  Your browser does not support the video tag.
  </video></div>
  <div style="vertical-align:middle; text-align: center;" >
  <img src="projects/srp-gru/gru.png" width="100%" height= "100%" alt="framework">
  </div>
</td>  
<td style="padding:20px;width:85%;vertical-align:middle">
  <a href="http://222.198.130.40:81/Qikan/Article/Detail?id=7103567009&from=Qikan_Search_Index">
    <papertitle>Deep End-to-end Super-resolution Perception Method for Load Data at Distribution Side</papertitle>
  </a>
  <br>
  <a>Guolong Liu</a>,
  <a>Junhua Zhao</a>,
  <a>Fushuan Wen</a>,
  <strong>Zhanxin Wu</strong>,
  <a>Yusheng Xue</a>

  <br>

  <em>Automation of Electric Power Systems</em>, 2020 <br>

  <a href="http://222.198.130.40:81/Qikan/Article/Detail?id=7103567009&from=Qikan_Search_Indexl">Paper</a>
  <p>
    Developed a deep end-to-end super resolution perception, recovered nearly 89% of high-frequency information lost in low-frequency information for equipment load identification 
    at 1/10th of the original data volume, communication, and storage requirements.
  </p>
</td>
</tr>





<!-- <tr bgcolor="#ffffd0">
</tr> -->
<!-- 
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
<heading>Academic Service</heading>
<td width="75%" valign="center">
</td> -->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
    <heading>Project</heading>
    <td style="padding:0px;width:15%;vertical-align:middle">
      <div class="one">
        <div class="two" id='tidy_image'><video  width=100% height=100% muted autoplay loop>
        <source src="projects/duckietown/duckietown_demo.mp4" type="video/mp4">
        Your browser does not support the video tag.
        </video>
        </div>
      </div>
    </td>
    <td style="padding:20px;width:85%;vertical-align:middle">
      <a>
        <papertitle>Autonomous Driving in Duckietown</papertitle>
      </a>
      
      <br>
      <strong>Zhanxin Wu</strong>,
      <a>Henrikus Theorizchy Cleven</a>
      <br>
  
      <em>NUS CS5478 Intelligent Robots: Algorithms and Systems</em>, 2023 <br>

      
      <!-- <a href="https://openreview.net/pdf?id=vuSI9mhDaBZ">Paper</a> -->
      <p>
        Developed a self-driving agent in the Duckietown simulation with classical planning, computer vision, and imitation learning techniques. Placed among the top-scored project in the module.
    </td>
  </tr>




<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
<heading>Teaching Assistant</heading>
<tr>
  <td width="100%" valign="center">
    CS5446/4246 AI Planning and Decision Making, Fall 2023, NUS</a>
    </br>
    DBA5106 Foundations of Business Analytics, Fall 2023, NUS</a>
    </br>
    CS5242 Neural Networks and Deep Learning, Spring 2023, NUS</a>
    </br>
    DBA5106 Foundations of Business Analytics, Fall 2022, NUS</a>
    </br>
    CSC4020 Fundamentals of Machine Learning, Spring 2022, CUHKSZ  
    </br>
    ERG3010 Data and Knowledge Management, Fall 2021, CUHKSZ
  </td>
</tr>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
<heading>Awards and Honors</heading>
  <tr>
    <td width="100%" valign="center">
    <div>2021: Dean's List, CUHKSZ School of Data Science </div>
    <div>2021: Academic Performance Scholarship, CUHKSZ </div>
    <div>2020: Dean's List, CUHKSZ School of Data Science </div>
    <div>2020: Academic Performance Scholarship, CUHKSZ </div>
    <div>2020: Undergraduate Research Award, CUHKSZ </div>
    </td>
  </tr>


</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
  <tr>
    <td style="padding:0px">
      <br>
      <p style="font-size:middle;text-align:right">
        Thank you for visiting my pawrent's website 🐾 🐾 🐾  <img src="general_images/dog1.jpg" width="6%" height= "6%" alt="framework">
      </p>
      <p style="text-align:right;font-size:small;">
        Template from <a href="https://jonbarron.info/" class="underline-on-hover">Jon Barron</a>. Last updated: Oct 2023
      </p>
    </td>
  </tr>
  </tbody>
</table>

</body>
</html>
